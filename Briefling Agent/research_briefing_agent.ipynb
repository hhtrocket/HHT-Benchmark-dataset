{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-title",
   "metadata": {},
   "source": "# Research Article Briefing Agent\n\nA **LangGraph**-based AI agent for discovering and summarizing academic papers.\n\n**Designed for:** Information Systems researchers studying AI agent evaluation in healthcare / data science.\n\n## Pipeline\n```\nSTART\n  → [Gate 1] Set date range + research topic + batch size\n  → Search academic papers (Tavily)\n  → [Gate 2a] Review papers in batches, select papers to include\n  → [Gate 2b] Set briefing focus prompt + word limit\n  → Generate structured briefings (LLM)\n  → [Gate 3] Review briefings, approve or request revisions\nEND\n```\n\n## Briefing Format (per paper)\n```\n**Title:** ...\n**Domain:** ...\n\n[Paragraph 1: Background, motivation, and problem addressed]\n\n[Paragraph 2: Methods, key findings, and implications]\n```\n\n## Setup Checklist\n1. Paste your API keys in **Cell 2**\n2. Adjust models / settings in **Cell 3**\n3. Run all cells in order\n4. Interact at each Human Gate (type your input and press Enter)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-install",
   "metadata": {},
   "source": "---\n## 1. Install Dependencies"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-install",
   "metadata": {},
   "outputs": [],
   "source": "!pip install -q langchain-openai langgraph tavily-python python-dotenv pydantic typing-extensions"
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-keys",
   "metadata": {},
   "source": "---\n## 2. API Keys\n\n- **LLM_API_KEY** — OpenRouter key ([openrouter.ai](https://openrouter.ai)) or your provider's key\n- **LLM_BASE_URL** — base URL for your LLM provider (`https://openrouter.ai/api/v1` for OpenRouter)\n- **TAVILY_API_KEY** — get one at [tavily.com](https://tavily.com) (free tier available)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-keys",
   "metadata": {},
   "outputs": [],
   "source": "import os\n\nos.environ[\"LLM_API_KEY\"]  = \"\"   # ← paste your LLM API key here\nos.environ[\"LLM_BASE_URL\"] = \"https://openrouter.ai/api/v1\"  # ← change if not OpenRouter\nos.environ[\"TAVILY_API_KEY\"] = \"\"  # ← paste your Tavily API key here\n\nassert os.environ[\"LLM_API_KEY\"],    \"⚠ Please fill in LLM_API_KEY above\"\nassert os.environ[\"TAVILY_API_KEY\"], \"⚠ Please fill in TAVILY_API_KEY above\"\nprint(\"API keys set.\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-config",
   "metadata": {},
   "source": "---\n## 3. Configuration"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-config",
   "metadata": {},
   "outputs": [],
   "source": "CFG = {\n    # ── LLM models ────────────────────────────────────────────────\n    # Change model IDs to match your provider.\n    # OpenRouter examples: \"openai/gpt-4o\", \"anthropic/claude-3.5-sonnet\", \"google/gemini-flash-1.5\"\n    \"models\": {\n        \"search_agent\": \"openai/gpt-4o\",   # used for query reformulation (optional, currently unused)\n        \"brief_agent\":  \"openai/gpt-4o\",   # used for briefing generation\n    },\n\n    # ── Search defaults ───────────────────────────────────────────\n    \"default_date_from\":    \"2024-01\",\n    \"default_date_to\":      \"2026-01\",\n    \"default_topic\":        \"AI agent evaluation healthcare data science\",\n    \"default_papers_per_batch\": 5,       # how many papers to show at once (1–10)\n    \"max_papers_to_fetch\":  20,           # total papers fetched from Tavily\n\n    # ── Briefing defaults ─────────────────────────────────────────\n    \"default_briefing_prompt\": \"summarize key contributions, methodology, and implications\",\n    \"default_word_limit\":      300,       # target words per briefing\n\n    # ── Control ───────────────────────────────────────────────────\n    \"max_revisions\":  3,                  # max briefing revision rounds\n}\n\nprint(\"Configuration loaded.\")\nfor k, v in CFG.items():\n    print(f\"  {k}: {v}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-imports",
   "metadata": {},
   "source": "---\n## 4. Imports, LLM Setup & Search Client"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-imports",
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport json\nimport operator\nimport textwrap\nfrom pathlib import Path\nfrom datetime import datetime\nfrom typing import Annotated, Literal\nfrom typing_extensions import TypedDict\n\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.messages import AIMessage, HumanMessage, SystemMessage\nfrom langgraph.graph import StateGraph, START, END\nfrom langgraph.types import interrupt, Command\nfrom langgraph.checkpoint.memory import MemorySaver\nfrom IPython.display import display, Markdown, HTML\n\n\n# ── LLM factory ──────────────────────────────────────────────────────────────\ndef _make_llm(model_id: str, max_tokens: int = 4096) -> ChatOpenAI:\n    return ChatOpenAI(\n        model=model_id,\n        base_url=os.environ.get(\"LLM_BASE_URL\", \"https://openrouter.ai/api/v1\"),\n        api_key=os.environ.get(\"LLM_API_KEY\", \"\"),\n        max_tokens=max_tokens,\n        max_retries=3,\n    )\n\nllm_brief = _make_llm(CFG[\"models\"][\"brief_agent\"], max_tokens=8192)\n\n# ── Tavily search client ──────────────────────────────────────────────────────\nfrom tavily import TavilyClient\n_tavily = TavilyClient(api_key=os.environ.get(\"TAVILY_API_KEY\", \"\"))\n\nprint(\"\\u2713 LLM and search client initialized\")\nprint(f\"  Brief agent:  {CFG['models']['brief_agent']}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-search",
   "metadata": {},
   "source": "---\n## 5. Academic Paper Search Tool"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-search-tool",
   "metadata": {},
   "outputs": [],
   "source": "# Academic domains to search — Tavily will prioritize these sources\nACADEMIC_DOMAINS = [\n    \"arxiv.org\",\n    \"semanticscholar.org\",\n    \"pubmed.ncbi.nlm.nih.gov\",\n    \"dl.acm.org\",\n    \"ieeexplore.ieee.org\",\n    \"springer.com\",\n    \"nature.com\",\n    \"sciencedirect.com\",\n    \"researchgate.net\",\n    \"scholar.google.com\",\n    \"wiley.com\",\n    \"tandfonline.com\",\n    \"jamanetwork.com\",\n    \"bmj.com\",\n    \"plos.org\",\n]\n\n\ndef search_academic_papers(\n    topic: str,\n    date_from: str,\n    date_to: str,\n    max_results: int = 20,\n) -> list[dict]:\n    \"\"\"\n    Search for academic papers using Tavily with academic domain filtering.\n\n    Args:\n        topic:       Research topic keywords\n        date_from:   Start date string, e.g. '2024-11'\n        date_to:     End date string,   e.g. '2026-01'\n        max_results: Maximum number of papers to return\n\n    Returns:\n        List of dicts with keys: index, title, url, abstract, source\n    \"\"\"\n    # Build query — include date context and academic keywords\n    query = f\"{topic} research paper academic {date_from} {date_to}\"\n    print(f\"  [Search] Query: {query[:100]}\")\n\n    try:\n        results = _tavily.search(\n            query=query,\n            max_results=max_results,\n            search_depth=\"advanced\",\n            include_domains=ACADEMIC_DOMAINS,\n        )\n        papers = []\n        for i, r in enumerate(results.get(\"results\", [])):\n            url = r.get(\"url\", \"\")\n            papers.append({\n                \"index\":    i + 1,\n                \"title\":    r.get(\"title\", \"Unknown Title\"),\n                \"url\":      url,\n                \"abstract\": r.get(\"content\", \"\")[:600].strip(),\n                \"source\":   url.split(\"/\")[2] if url else \"unknown\",\n                \"score\":    round(r.get(\"score\", 0.0), 3),\n            })\n        return papers\n\n    except Exception as e:\n        print(f\"  [WARNING] Search failed: {e}\")\n        return []\n\n\nprint(\"\\u2713 Search tool defined\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-state",
   "metadata": {},
   "source": "---\n## 6. State Schema"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-state",
   "metadata": {},
   "outputs": [],
   "source": "class BriefingAgentState(TypedDict):\n    \"\"\"Full state of the Research Briefing Agent.\"\"\"\n\n    # ── Phase 1: Search parameters ────────────────────────────────\n    date_from:          str   # e.g. \"2024-11\"\n    date_to:            str   # e.g. \"2026-01\"\n    search_topic:       str   # e.g. \"patient EHR AI agent evaluation\"\n    papers_per_batch:   int   # 1–10, how many papers to display at once\n\n    # ── Phase 2: Search results ───────────────────────────────────\n    all_papers:         list  # All found papers: [{index, title, url, abstract, source}]\n    shown_up_to:        int   # Pagination cursor (how many papers have been shown)\n    selected_indices:   list  # 1-based paper indices chosen by human\n\n    # ── Phase 3: Briefing parameters ─────────────────────────────\n    briefing_prompt:    str   # What aspect to focus on\n    word_limit:         int   # Target word count per briefing\n\n    # ── Outputs ───────────────────────────────────────────────────\n    briefings:          list  # Generated briefing texts (one per selected paper)\n\n    # ── Human feedback at each gate ───────────────────────────────\n    hf_search:          str   # Gate 1 feedback\n    hf_papers:          str   # Gate 2a feedback (\"more\" | \"search_again\" | \"selected\")\n    hf_briefing:        str   # Gate 3 feedback\n\n    # ── Control ───────────────────────────────────────────────────\n    revision_round:     int\n    status:             str\n    messages:           Annotated[list, operator.add]\n\n\nprint(\"\\u2713 State schema defined\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-nodes",
   "metadata": {},
   "source": "---\n## 7. Agent Nodes"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-gate1",
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# GATE 1 — Search Setup\n# Human sets: date range | topic | papers per batch\n# ============================================================\n\ndef search_setup_gate(state: dict) -> dict:\n    \"\"\"Interrupt: collect search parameters from the human.\"\"\"\n    print(\"\\n\" + \"=\" * 70)\n    print(\"GATE 1: Search Setup\")\n    print(\"=\" * 70)\n\n    prompt = textwrap.dedent(f\"\"\"\\\n        ## Research Paper Search Setup\n\n        Please enter your search parameters in **pipe-separated** format:\n\n        ```\n        <date_from> | <date_to> | <topic> | <papers_per_batch>\n        ```\n\n        | Field              | Example                                      |\n        |--------------------|----------------------------------------------|\n        | `date_from`        | `2024-11`  (November 2024)                  |\n        | `date_to`          | `2026-01`  (January 2026)                   |\n        | `topic`            | `patient EHR AI agent evaluation`           |\n        | `papers_per_batch` | `5`  (1–10 papers shown at a time)          |\n\n        **Example input:**\n        ```\n        2024-11 | 2026-01 | AI agent evaluation in healthcare EHR | 5\n        ```\n\n        *Press Enter to use defaults: `{CFG['default_date_from']} | {CFG['default_date_to']} | {CFG['default_topic']} | {CFG['default_papers_per_batch']}`*\n    \"\"\")\n\n    feedback = interrupt(prompt)\n    feedback = str(feedback).strip()\n\n    # Use defaults if blank\n    if not feedback or feedback.lower() in (\"approve\", \"approved\", \"ok\", \"default\"):\n        feedback = (\n            f\"{CFG['default_date_from']} | {CFG['default_date_to']} \"\n            f\"| {CFG['default_topic']} | {CFG['default_papers_per_batch']}\"\n        )\n\n    # Parse pipe-separated input\n    parts = [p.strip() for p in feedback.split(\"|\")]\n    date_from = parts[0] if len(parts) > 0 and parts[0] else CFG[\"default_date_from\"]\n    date_to   = parts[1] if len(parts) > 1 and parts[1] else CFG[\"default_date_to\"]\n    topic     = parts[2] if len(parts) > 2 and parts[2] else CFG[\"default_topic\"]\n    try:\n        batch = max(1, min(10, int(parts[3]))) if len(parts) > 3 else CFG[\"default_papers_per_batch\"]\n    except (ValueError, IndexError):\n        batch = CFG[\"default_papers_per_batch\"]\n\n    print(f\"  Date range:  {date_from} → {date_to}\")\n    print(f\"  Topic:       {topic}\")\n    print(f\"  Batch size:  {batch}\")\n\n    return {\n        \"date_from\":          date_from,\n        \"date_to\":            date_to,\n        \"search_topic\":       topic,\n        \"papers_per_batch\":   batch,\n        \"hf_search\":          \"approved\",\n        \"shown_up_to\":        0,\n        \"selected_indices\":   [],\n        \"all_papers\":         [],\n        \"briefings\":          [],\n        \"revision_round\":     0,\n        \"status\":             \"searching\",\n        \"messages\":           [AIMessage(content=f\"Searching for: *{topic}* ({date_from} → {date_to})\")],\n    }"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-search-node",
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# NODE — Search Papers\n# ============================================================\n\ndef do_search(state: dict) -> dict:\n    \"\"\"Call Tavily to fetch academic papers matching the topic and date range.\"\"\"\n    print(\"\\n\" + \"=\" * 70)\n    print(\"NODE: Searching for Academic Papers\")\n    print(\"=\" * 70)\n\n    topic     = state.get(\"search_topic\",  CFG[\"default_topic\"])\n    date_from = state.get(\"date_from\",     CFG[\"default_date_from\"])\n    date_to   = state.get(\"date_to\",       CFG[\"default_date_to\"])\n\n    papers = search_academic_papers(\n        topic=topic,\n        date_from=date_from,\n        date_to=date_to,\n        max_results=CFG[\"max_papers_to_fetch\"],\n    )\n\n    print(f\"  Found {len(papers)} papers\")\n    for p in papers[:3]:\n        print(f\"    [{p['index']}] {p['title'][:70]}...\")\n    if len(papers) > 3:\n        print(f\"    ... and {len(papers) - 3} more\")\n\n    return {\n        \"all_papers\":  papers,\n        \"shown_up_to\": 0,\n        \"messages\":    [AIMessage(content=f\"Found **{len(papers)}** papers on *{topic}*.\")],\n    }"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-gate2a",
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# GATE 2a — Paper Review & Selection\n# Shows papers in batches; human selects papers to include\n# ============================================================\n\ndef paper_review_gate(state: dict) -> dict:\n    \"\"\"Interrupt: display current batch of papers; human selects or asks for more.\"\"\"\n    print(\"\\n\" + \"=\" * 70)\n    print(\"GATE 2a: Paper Review & Selection\")\n    print(\"=\" * 70)\n\n    all_papers  = state.get(\"all_papers\", [])\n    shown_up_to = state.get(\"shown_up_to\", 0)\n    batch_size  = state.get(\"papers_per_batch\", CFG[\"default_papers_per_batch\"])\n    total       = len(all_papers)\n\n    # Slice the current batch\n    batch     = all_papers[shown_up_to : shown_up_to + batch_size]\n    batch_end = min(shown_up_to + batch_size, total)\n\n    # ── Build display content ────────────────────────────────────\n    if not all_papers:\n        content = \"\\u26a0\\ufe0f No papers were found. Please try different search parameters.\\n\\nType `search: <new topic>` to search again.\"\n    elif not batch:\n        content = f\"\\u26a0\\ufe0f All **{total}** papers have been shown.\\n\\n\"\n        content += \"Please select papers to include (e.g., `1,3,5`) or type `search: <new topic>` to search again.\"\n    else:\n        content = f\"## Papers Found — Showing {shown_up_to+1}\\u2013{batch_end} of {total}\\n\\n\"\n        for p in batch:\n            content += f\"---\\n\"\n            content += f\"**{p['index']}. {p['title']}**\\n\\n\"\n            content += f\"- **Source:** {p['source']}  \\n\"\n            content += f\"- **URL:** {p['url']}  \\n\"\n            content += f\"- **Abstract:** {p['abstract'][:350]}...\\n\\n\"\n\n        content += \"---\\n\"\n        content += \"**Commands:**\\n\"\n        content += \"- Select papers: type numbers separated by commas, e.g. `1,3,5`\\n\"\n        if batch_end < total:\n            content += \"- See next batch: type `more`\\n\"\n        content += \"- Search again: type `search: <new topic>`\\n\"\n        content += f\"\\n*({total - batch_end} more papers available)*\" if batch_end < total else \"\"\n\n    feedback = interrupt(content)\n    feedback = str(feedback).strip()\n    print(f\"  Input: {feedback[:80]}\")\n\n    # ── Parse feedback ──────────────────────────────────────────\n    if feedback.lower() == \"more\":\n        # Show next batch\n        return {\n            \"shown_up_to\": shown_up_to + batch_size,\n            \"hf_papers\":   \"more\",\n        }\n\n    elif feedback.lower().startswith(\"search:\"):\n        # New search\n        new_topic = feedback[7:].strip()\n        print(f\"  New topic: {new_topic}\")\n        return {\n            \"search_topic\": new_topic,\n            \"hf_papers\":    \"search_again\",\n            \"shown_up_to\":  0,\n            \"all_papers\":   [],\n        }\n\n    else:\n        # Parse paper selection — e.g. \"1,3,5\" or \"1 3 5\" or \"1-3\"\n        # Support comma and space separation\n        tokens = feedback.replace(\",\", \" \").split()\n        indices = []\n        for tok in tokens:\n            # Handle ranges like \"1-3\"\n            if \"-\" in tok:\n                try:\n                    a, b = tok.split(\"-\", 1)\n                    indices.extend(range(int(a), int(b) + 1))\n                except ValueError:\n                    pass\n            elif tok.isdigit():\n                indices.append(int(tok))\n\n        # Validate indices\n        valid_indices = [p[\"index\"] for p in all_papers]\n        indices = [i for i in indices if i in valid_indices]\n\n        # Default: select all shown papers if no valid input\n        if not indices:\n            indices = [p[\"index\"] for p in batch]\n            print(f\"  No valid selection parsed — defaulting to shown batch: {indices}\")\n        else:\n            print(f\"  Selected indices: {indices}\")\n\n        return {\n            \"selected_indices\": indices,\n            \"hf_papers\":        \"selected\",\n        }"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-gate2b",
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# GATE 2b — Briefing Parameter Setup\n# Human sets: focus prompt | word limit\n# ============================================================\n\ndef briefing_setup_gate(state: dict) -> dict:\n    \"\"\"Interrupt: human sets briefing focus and word count.\"\"\"\n    print(\"\\n\" + \"=\" * 70)\n    print(\"GATE 2b: Briefing Parameters\")\n    print(\"=\" * 70)\n\n    all_papers       = state.get(\"all_papers\", [])\n    selected_indices = state.get(\"selected_indices\", [])\n    selected_papers  = [p for p in all_papers if p[\"index\"] in selected_indices]\n\n    # Build list of selected paper titles\n    titles_md = \"\\n\".join(\n        f\"  {i+1}. {p['title']}\"\n        for i, p in enumerate(selected_papers)\n    )\n\n    content = textwrap.dedent(f\"\"\"\\\n        ## Briefing Parameters\n\n        **You selected {len(selected_papers)} paper(s):**\n        {titles_md}\n\n        ---\n\n        Please set briefing parameters in **pipe-separated** format:\n\n        ```\n        <focus prompt> | <word limit>\n        ```\n\n        | Field          | Description                                               | Example |\n        |----------------|-----------------------------------------------------------|---------|\n        | `focus prompt` | What to explain in the briefing                           | `explain the methodology, key findings, and clinical impact` |\n        | `word limit`   | Target words per briefing (recommended: 250–500)          | `350` |\n\n        **Example input:**\n        ```\n        focus on evaluation methodology and clinical implications | 350\n        ```\n\n        *Press Enter for defaults: `{CFG['default_briefing_prompt']} | {CFG['default_word_limit']}`*\n    \"\"\")\n\n    feedback = interrupt(content)\n    feedback = str(feedback).strip()\n\n    # Use defaults if blank\n    if not feedback or feedback.lower() in (\"approve\", \"approved\", \"ok\", \"default\"):\n        feedback = f\"{CFG['default_briefing_prompt']} | {CFG['default_word_limit']}\"\n\n    parts = [p.strip() for p in feedback.split(\"|\")]\n    briefing_prompt = parts[0] if parts and parts[0] else CFG[\"default_briefing_prompt\"]\n    try:\n        word_limit = int(parts[1]) if len(parts) > 1 else CFG[\"default_word_limit\"]\n        word_limit = max(100, min(1000, word_limit))  # clamp 100–1000\n    except (ValueError, IndexError):\n        word_limit = CFG[\"default_word_limit\"]\n\n    print(f\"  Focus prompt: {briefing_prompt}\")\n    print(f\"  Word limit:   {word_limit} words per briefing\")\n\n    return {\n        \"briefing_prompt\": briefing_prompt,\n        \"word_limit\":       word_limit,\n    }"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-generate",
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# NODE — Generate Briefings\n# LLM generates structured briefings for each selected paper\n# ============================================================\n\nBRIEF_SYSTEM_PROMPT = textwrap.dedent(\"\"\"\\\n    You are an expert academic research summarizer specializing in\n    Information Systems, AI/ML, and healthcare informatics.\n\n    For EACH paper you receive, write a structured briefing using\n    EXACTLY this format (no deviations):\n\n    ---\n    **Title:** [full paper title]\n    **Domain:** [1–3 word research domain, e.g., \"Healthcare AI\", \"Clinical NLP\",\n                 \"EHR Systems\", \"AI Agent Evaluation\", \"Data Science\"]\n\n    [Paragraph 1 — 2–4 sentences: background, motivation, and the specific\n     research problem or gap this paper addresses.]\n\n    [Paragraph 2 — 2–4 sentences: methods, key results, and contributions or\n     implications for the field.]\n\n    ---\n\n    Rules:\n    - Stay within the requested word limit.\n    - Be specific and evidence-based; avoid vague language.\n    - Incorporate any revision feedback if provided.\n    - Focus on: {focus}\n\"\"\")\n\n\ndef generate_briefings(state: dict) -> dict:\n    \"\"\"Generate structured briefings for all selected papers using the LLM.\"\"\"\n    print(\"\\n\" + \"=\" * 70)\n    print(\"NODE: Generating Briefings\")\n    print(\"=\" * 70)\n\n    all_papers       = state.get(\"all_papers\", [])\n    selected_indices = state.get(\"selected_indices\", [])\n    selected_papers  = [p for p in all_papers if p[\"index\"] in selected_indices]\n\n    briefing_prompt = state.get(\"briefing_prompt\", CFG[\"default_briefing_prompt\"])\n    word_limit      = state.get(\"word_limit\",      CFG[\"default_word_limit\"])\n    revision_round  = state.get(\"revision_round\",  0)\n    prior_feedback  = state.get(\"hf_briefing\",     \"\")\n\n    print(f\"  Papers:    {len(selected_papers)}\")\n    print(f\"  Focus:     {briefing_prompt}\")\n    print(f\"  Words:     ~{word_limit} per briefing\")\n    if revision_round > 0:\n        print(f\"  Revision:  round {revision_round} (feedback: {prior_feedback[:60]})\")\n\n    system_prompt = BRIEF_SYSTEM_PROMPT.format(focus=briefing_prompt)\n\n    all_briefings = []\n    for i, paper in enumerate(selected_papers):\n        title_short = paper[\"title\"][:65]\n        print(f\"  [{i+1}/{len(selected_papers)}] {title_short}...\")\n\n        feedback_note = (\n            f\"\\n\\nRevision feedback from human reviewer: {prior_feedback}\"\n            if prior_feedback and prior_feedback != \"approved\"\n            else \"\"\n        )\n\n        user_msg = textwrap.dedent(f\"\"\"\\\n            Paper {i+1}:\n            Title:    {paper['title']}\n            Source:   {paper['source']}\n            URL:      {paper['url']}\n            Abstract: {paper['abstract']}\n            {feedback_note}\n\n            Write a briefing of approximately {word_limit} words.\n        \"\"\")\n\n        try:\n            resp = llm_brief.invoke([\n                SystemMessage(content=system_prompt),\n                HumanMessage(content=user_msg),\n            ])\n            briefing_text = resp.content.strip()\n        except Exception as e:\n            print(f\"    [WARNING] LLM call failed: {e}\")\n            briefing_text = (\n                f\"---\\n**Title:** {paper['title']}\\n\"\n                f\"**Domain:** Unknown\\n\\n[Generation failed: {e}]\\n---\"\n            )\n\n        all_briefings.append(briefing_text)\n        word_count = len(briefing_text.split())\n        print(f\"    \\u2713 {word_count} words generated\")\n\n    print(f\"\\n  Total: {len(all_briefings)} briefings\")\n\n    return {\n        \"briefings\": all_briefings,\n        \"status\":    \"pending_review\",\n        \"messages\":  [AIMessage(content=f\"Generated **{len(all_briefings)}** briefings.\")],\n    }"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-gate3",
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# GATE 3 — Final Review\n# Human reviews briefings, approves or requests revisions\n# ============================================================\n\ndef final_review_gate(state: dict) -> dict:\n    \"\"\"Interrupt: display all generated briefings for human approval.\"\"\"\n    print(\"\\n\" + \"=\" * 70)\n    print(\"GATE 3: Final Review\")\n    print(\"=\" * 70)\n\n    briefings      = state.get(\"briefings\", [])\n    revision_round = state.get(\"revision_round\", 0)\n    max_rev        = CFG[\"max_revisions\"]\n\n    # Compose full briefing display\n    if briefings:\n        all_briefings_text = \"\\n\\n\".join(briefings)\n    else:\n        all_briefings_text = \"_No briefings were generated._\"\n\n    revision_note = (\n        f\"\\n\\n> \\u26a0\\ufe0f Max revisions ({max_rev}) reached — this is the final version.\"\n        if revision_round >= max_rev\n        else f\"\\n\\n> Revision round {revision_round}/{max_rev} — you may request {max_rev - revision_round} more revision(s).\"\n    )\n\n    content = textwrap.dedent(f\"\"\"\\\n        ## Generated Briefings ({len(briefings)} paper(s))\n\n        {all_briefings_text}\n\n        ---\n        {revision_note}\n\n        **Options:**\n        - Press Enter or type `approve` → save and finish\n        - Type feedback → revise all briefings (e.g., \"make paragraph 2 more concise\")\n        - Type `reselect` → go back to paper selection\n    \"\"\")\n\n    feedback = interrupt(content)\n    feedback = str(feedback).strip()\n\n    # Approved?\n    is_approved = not feedback or feedback.lower() in (\n        \"approve\", \"approved\", \"ok\", \"yes\", \"lgtm\", \"looks good\"\n    )\n\n    if is_approved or revision_round >= max_rev:\n        if not is_approved:\n            print(f\"  ** Max revisions ({max_rev}) reached — finalizing **\")\n        print(\"  \\u2192 Approved\")\n        return {\"hf_briefing\": \"approved\", \"status\": \"complete\"}\n\n    if feedback.lower() == \"reselect\":\n        print(\"  \\u2192 Going back to paper selection\")\n        return {\n            \"hf_briefing\":      \"reselect\",\n            \"selected_indices\": [],\n            \"briefings\":        [],\n            \"shown_up_to\":      0,\n        }\n\n    print(f\"  \\u2192 Revision requested (round {revision_round+1}): {feedback[:80]}\")\n    return {\n        \"hf_briefing\":   feedback,\n        \"revision_round\": revision_round + 1,\n    }"
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-routing",
   "metadata": {},
   "source": "---\n## 8. Routing Functions"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-routing",
   "metadata": {},
   "outputs": [],
   "source": "def route_after_paper_review(\n    state: dict,\n) -> Literal[\"paper_review_gate\", \"do_search\", \"briefing_setup_gate\"]:\n    \"\"\"After Gate 2a: show more papers, search again, or proceed to briefing setup.\"\"\"\n    hf = state.get(\"hf_papers\", \"\")\n    if hf == \"more\":\n        return \"paper_review_gate\"     # show next batch\n    elif hf == \"search_again\":\n        return \"do_search\"              # new search with updated topic\n    else:\n        return \"briefing_setup_gate\"   # papers selected → set briefing params\n\n\ndef route_after_final_review(\n    state: dict,\n) -> Literal[\"generate_briefings\", \"paper_review_gate\", \"__end__\"]:\n    \"\"\"After Gate 3: approve → end, reselect → paper review, else → revise.\"\"\"\n    hf = state.get(\"hf_briefing\", \"\")\n    if hf == \"approved\":\n        return \"__end__\"\n    elif hf == \"reselect\":\n        return \"paper_review_gate\"\n    else:\n        return \"generate_briefings\"\n\n\nprint(\"\\u2713 Routing functions defined\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-graph",
   "metadata": {},
   "source": "---\n## 9. Build Graph"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-build-graph",
   "metadata": {},
   "outputs": [],
   "source": "def build_graph(checkpointer=None):\n    \"\"\"\n    Build the Research Briefing Agent graph.\n\n    Graph structure:\n        START\n          → search_setup_gate   [Gate 1: date + topic + batch]\n          → do_search           [Tavily search]\n          → paper_review_gate   [Gate 2a: show papers, get selection]\n              ↑ (more / search_again loop)\n          → briefing_setup_gate [Gate 2b: focus prompt + word limit]\n          → generate_briefings  [LLM generates briefings]\n          → final_review_gate   [Gate 3: approve or revise]\n              ↓ (revise loop / reselect loop)\n        END\n    \"\"\"\n    g = StateGraph(BriefingAgentState)\n\n    # ── Register nodes ──────────────────────────────────────────\n    g.add_node(\"search_setup_gate\",   search_setup_gate)\n    g.add_node(\"do_search\",           do_search)\n    g.add_node(\"paper_review_gate\",   paper_review_gate)\n    g.add_node(\"briefing_setup_gate\", briefing_setup_gate)\n    g.add_node(\"generate_briefings\",  generate_briefings)\n    g.add_node(\"final_review_gate\",   final_review_gate)\n\n    # ── Phase 1: Search setup ────────────────────────────────────\n    g.add_edge(START, \"search_setup_gate\")\n    g.add_edge(\"search_setup_gate\", \"do_search\")\n\n    # ── Phase 2a: Paper review loop ──────────────────────────────\n    g.add_edge(\"do_search\", \"paper_review_gate\")\n    g.add_conditional_edges(\n        \"paper_review_gate\",\n        route_after_paper_review,\n        {\n            \"paper_review_gate\":   \"paper_review_gate\",   # show more\n            \"do_search\":           \"do_search\",            # search again\n            \"briefing_setup_gate\": \"briefing_setup_gate\", # proceed\n        },\n    )\n\n    # ── Phase 2b → 3: Briefing generation ───────────────────────\n    g.add_edge(\"briefing_setup_gate\", \"generate_briefings\")\n    g.add_edge(\"generate_briefings\",  \"final_review_gate\")\n    g.add_conditional_edges(\n        \"final_review_gate\",\n        route_after_final_review,\n        {\n            \"generate_briefings\": \"generate_briefings\",  # revise\n            \"paper_review_gate\":  \"paper_review_gate\",   # reselect\n            \"__end__\":            END,                   # done\n        },\n    )\n\n    return g.compile(checkpointer=checkpointer)\n\n\n# Build the graph\nagent = build_graph(checkpointer=MemorySaver())\n\nprint(\"=\" * 60)\nprint(\"GRAPH BUILT — Research Briefing Agent\")\nprint(\"=\" * 60)\nprint(f\"  Nodes: {len(agent.get_graph().nodes)}\")\nprint(f\"  Edges: {len(agent.get_graph().edges)}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-run",
   "metadata": {},
   "source": "---\n## 10. Run the Agent (Interactive)\n\nThe cell below runs the full pipeline.\n\n- At each **Human Gate**, the agent will display content as rendered Markdown and wait for your input.\n- **Press Enter** (or type `approve`) to accept.\n- **Type feedback or commands** to navigate (see each gate's instructions)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-run",
   "metadata": {},
   "outputs": [],
   "source": "import time\n\n# ── Fresh run configuration ──────────────────────────────────────────────────\nconfig     = {\"configurable\": {\"thread_id\": f\"briefing-{datetime.now().strftime('%Y%m%d_%H%M%S')}\"}}\ngate_num   = 0\n\n# ── Start the agent ──────────────────────────────────────────────────────────\nprint(\"Starting Research Briefing Agent...\")\nprint(\"=\" * 70)\nt0 = time.time()\n\nresult = agent.invoke({}, config)\n\n# ── Interactive loop: handle each interrupt gate ─────────────────────────────\nwhile True:\n    snapshot = agent.get_state(config)\n    if not snapshot.next:\n        break  # graph completed\n\n    # Render the interrupt content\n    for task in snapshot.tasks:\n        if hasattr(task, \"interrupts\"):\n            for intr in task.interrupts:\n                gate_num += 1\n                display(HTML(\"<hr style='border:3px solid #2E75B6; margin:24px 0 8px 0'>\"))\n                display(Markdown(f\"### \\u25b6 Human Gate {gate_num}\"))\n                display(Markdown(str(intr.value)))\n                display(HTML(\"<hr style='border:1px solid #ccc; margin:8px 0 16px 0'>\"))\n\n    # Get human input\n    feedback = input(\"> \").strip()\n    if not feedback:\n        feedback = \"approved\"\n\n    # Resume the graph\n    result = agent.invoke(Command(resume=feedback), config)\n\n# ── Completion ───────────────────────────────────────────────────────────────\nelapsed = time.time() - t0\ndisplay(HTML(\"<hr style='border:4px solid #1B2A4A; margin:24px 0'>\"))\ndisplay(Markdown(\"## \\u2705 Agent Complete\"))\nprint(f\"Elapsed: {elapsed:.0f}s\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-results",
   "metadata": {},
   "source": "---\n## 11. View & Save Results"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-view-results",
   "metadata": {},
   "outputs": [],
   "source": "# ── Display final briefings ───────────────────────────────────────────────────\nbriefings = result.get(\"briefings\", [])\n\nif briefings:\n    display(Markdown(f\"## Research Briefings ({len(briefings)} papers)\"))\n    for i, brief in enumerate(briefings):\n        display(HTML(f\"<h4>Briefing {i+1}</h4>\"))\n        display(Markdown(brief))\n        display(HTML(\"<hr>\"))\nelse:\n    print(\"No briefings were generated.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-save-results",
   "metadata": {},
   "outputs": [],
   "source": "import yaml\n\n# ── Output directory ──────────────────────────────────────────────────────────\nts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\noutput_dir = Path(ts)\noutput_dir.mkdir(parents=True, exist_ok=True)\n\nbriefings       = result.get(\"briefings\", [])\nsearch_topic    = result.get(\"search_topic\", \"unknown\")\nselected_papers = [\n    p for p in result.get(\"all_papers\", [])\n    if p[\"index\"] in result.get(\"selected_indices\", [])\n]\n\n# ── Markdown report ───────────────────────────────────────────────────────────\nmd_path = output_dir / f\"briefings_{ts}.md\"\nwith open(md_path, \"w\", encoding=\"utf-8\") as f:\n    f.write(f\"# Research Briefings\\n\\n\")\n    f.write(f\"**Topic:** {search_topic}  \\n\")\n    f.write(f\"**Date range:** {result.get('date_from', '?')} – {result.get('date_to', '?')}  \\n\")\n    f.write(f\"**Generated:** {datetime.now().isoformat()}  \\n\")\n    f.write(f\"**Papers:** {len(briefings)}  \\n\")\n    f.write(f\"**Focus prompt:** {result.get('briefing_prompt', '?')}  \\n\\n\")\n    f.write(\"---\\n\\n\")\n    for i, brief in enumerate(briefings):\n        f.write(brief)\n        f.write(\"\\n\\n---\\n\\n\")\nprint(f\"Markdown saved: {md_path}\")\n\n# ── Metadata YAML ─────────────────────────────────────────────────────────────\nmeta_path = output_dir / \"meta.yaml\"\nwith open(meta_path, \"w\", encoding=\"utf-8\") as f:\n    yaml.dump({\n        \"timestamp\":      datetime.now().isoformat(),\n        \"topic\":          search_topic,\n        \"date_from\":      result.get(\"date_from\", \"\"),\n        \"date_to\":        result.get(\"date_to\", \"\"),\n        \"briefing_prompt\":result.get(\"briefing_prompt\", \"\"),\n        \"word_limit\":     result.get(\"word_limit\", 0),\n        \"total_papers_found\":   len(result.get(\"all_papers\", [])),\n        \"selected_papers\":      len(briefings),\n        \"model\":          CFG[\"models\"][\"brief_agent\"],\n        \"elapsed_seconds\": round(elapsed, 1),\n        \"papers\": [\n            {\"index\": p[\"index\"], \"title\": p[\"title\"], \"url\": p[\"url\"]}\n            for p in selected_papers\n        ],\n    }, f, default_flow_style=False, sort_keys=False, allow_unicode=True)\nprint(f\"Metadata saved: {meta_path}\")\n\n# ── List saved files ──────────────────────────────────────────────────────────\nprint(f\"\\nOutput directory: {output_dir.resolve()}\")\nfor p in sorted(output_dir.iterdir()):\n    print(f\"  {p.name:45s} {p.stat().st_size:>8,} bytes\")"
  }
 ]
}
