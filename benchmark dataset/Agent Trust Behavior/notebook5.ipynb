{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 5. Agent Trust Behavior\n",
    "**Category:** AI Agent Core Capabilities\n",
    "\n",
    "**Source:** [CAMEL-AI / agent-trust](https://github.com/camel-ai/agent-trust)\n",
    "\n",
    "**Description:** Used for game theory research to train agents on decision-making\n",
    "logic regarding trust, betrayal, and reciprocity.\n",
    "\n",
    "**Data Content:** Multi-turn interaction logs from Trust Games, including records\n",
    "of the agent's Belief, Desire, and Intention (BDI).\n",
    "\n",
    "**Paper:** [Can Large Language Models Serve as Rational Players in Game Theory?](https://arxiv.org/abs/2310.01983)\n",
    "\n",
    "---\n",
    "\n",
    "**This notebook covers:**\n",
    "1. Data loading & parsing of game JSON results\n",
    "2. Game type classification (Trust, Dictator, Risky Dictator, Lottery, Trust Problem)\n",
    "3. Per-model giving behavior analysis (box plots, mean comparisons)\n",
    "4. Persona effects: baseline vs persona-based decisions\n",
    "5. Demographic bias analysis across race & gender personas\n",
    "6. Summary statistics & key observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (uncomment if needed)\n",
    "# !pip install pandas matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "plt.rcParams[\"axes.titlesize\"] = 13\n",
    "plt.rcParams[\"axes.labelsize\"] = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Dataset Overview\n",
    "\n",
    "The agent-trust dataset records behavioral economics experiments where LLM agents\n",
    "play classic game theory scenarios. Each agent is assigned a persona (name, age,\n",
    "gender, profession, personality) and makes decisions using a **Belief-Desire-Intention\n",
    "(BDI)** framework.\n",
    "\n",
    "**Game types:**\n",
    "\n",
    "| Game | Description | Decision |\n",
    "|------|-------------|----------|\n",
    "| **Trust Game** | Give $N (tripled) to a player who may return some | Dollar amount (0-10) |\n",
    "| **Dictator Game** | Give $N (tripled) to a player, no return expected | Dollar amount (0-10) |\n",
    "| **Risky Dictator Problem** | Trust/not trust with probabilistic payoffs | trust / not trust |\n",
    "| **Trust Problem** | Trust/not trust with reciprocal decisions | trust / not trust |\n",
    "| **Lottery Problem** | Fixed vs. probabilistic payoff comparison | trust / not trust |\n",
    "\n",
    "**Models tested:** GPT-4, GPT-3.5-Turbo, LLaMA-2 (7B/13B/70B), Vicuna (7B/13B/33B)\n",
    "\n",
    "**Experiment variants:**\n",
    "- `res/`: Baseline (no demographic persona)\n",
    "- `person_res/`: With persona (name, age, gender, profession, personality)\n",
    "- `male_res/`, `female_res/`: Gender-specific personas\n",
    "- `African American_res/`, `Asian American_res/`, etc.: Race-specific personas\n",
    "- `COT_res/`: Chain-of-Thought prompting\n",
    "- `more_trust_2_res/`, `less_trust_2_res/`: Trust-biased personas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 3. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository (skip if already cloned)\n",
    "REPO_DIR = Path(\"agent-trust\")\n",
    "if not REPO_DIR.exists():\n",
    "    os.system(\"git clone https://github.com/camel-ai/agent-trust.git\")\n",
    "    print(\"Repository cloned.\")\n",
    "else:\n",
    "    print(f\"Repository already exists at {REPO_DIR}\")\n",
    "\n",
    "DATA_DIR = REPO_DIR / \"agent_trust\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available experiment directories\n",
    "no_repeat_dir = DATA_DIR / \"No repeated res\"\n",
    "repeat_dir = DATA_DIR / \"repeated res\"\n",
    "\n",
    "print(\"=== Non-Repeated Experiment Variants ===\")\n",
    "for d in sorted(no_repeat_dir.iterdir()):\n",
    "    if d.is_dir():\n",
    "        print(f\"  {d.name}/\")\n",
    "\n",
    "print(f\"\\n=== Repeated Experiment Variants ===\")\n",
    "for d in sorted(repeat_dir.iterdir()):\n",
    "    if d.is_dir():\n",
    "        print(f\"  {d.name}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "### 3.1 Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_game_json(filepath):\n",
    "    \"\"\"Load a game result JSON and return a list of record dicts.\"\"\"\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    records = []\n",
    "    res_list = data.get(\"res\", [])\n",
    "    dialog_list = data.get(\"dialog\", [])\n",
    "\n",
    "    if isinstance(res_list, list) and isinstance(dialog_list, list):\n",
    "        for i in range(min(len(res_list), len(dialog_list))):\n",
    "            entry = dialog_list[i]\n",
    "            record = {\n",
    "                \"decision\": res_list[i],\n",
    "                \"index\": entry[0] if len(entry) > 0 else i,\n",
    "                \"persona\": entry[1] if len(entry) > 1 else \"\",\n",
    "                \"response\": entry[2] if len(entry) > 2 else \"\",\n",
    "            }\n",
    "            records.append(record)\n",
    "    return records\n",
    "\n",
    "\n",
    "def load_all_games(variant_dir):\n",
    "    \"\"\"Load all game JSON files from a model's result directory.\"\"\"\n",
    "    all_records = []\n",
    "    if not variant_dir.exists():\n",
    "        return all_records\n",
    "\n",
    "    for json_file in sorted(variant_dir.glob(\"*.json\")):\n",
    "        records = load_game_json(json_file)\n",
    "        for r in records:\n",
    "            r[\"filename\"] = json_file.stem\n",
    "            r[\"source_file\"] = json_file.name\n",
    "        all_records.extend(records)\n",
    "    return all_records\n",
    "\n",
    "\n",
    "def classify_game(filename):\n",
    "    \"\"\"Classify game type from filename.\"\"\"\n",
    "    fname = filename.lower()\n",
    "    if \"trust_game\" in fname:\n",
    "        return \"Trust Game\"\n",
    "    elif \"dictator_game\" in fname:\n",
    "        return \"Dictator Game\"\n",
    "    elif \"risky_dictator\" in fname:\n",
    "        return \"Risky Dictator\"\n",
    "    elif \"trust_problem\" in fname or \"map_trust\" in fname:\n",
    "        return \"Trust Problem\"\n",
    "    elif \"lottery\" in fname:\n",
    "        return \"Lottery Problem\"\n",
    "    else:\n",
    "        return \"Other\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "### 3.2 Load Baseline & Persona Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load non-repeated baseline results (no persona)\n",
    "baseline_dir = no_repeat_dir / \"res\"\n",
    "all_baseline = []\n",
    "\n",
    "for model_dir in sorted(baseline_dir.iterdir()):\n",
    "    if model_dir.is_dir():\n",
    "        model_name = model_dir.name.replace(\"_res\", \"\")\n",
    "        records = load_all_games(model_dir)\n",
    "        for r in records:\n",
    "            r[\"model\"] = model_name\n",
    "        all_baseline.extend(records)\n",
    "\n",
    "df_baseline = pd.DataFrame(all_baseline)\n",
    "df_baseline[\"game_type\"] = df_baseline[\"filename\"].apply(classify_game)\n",
    "\n",
    "print(f\"Baseline records loaded: {df_baseline.shape}\")\n",
    "print(f\"Models: {df_baseline['model'].unique().tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load persona-based results\n",
    "persona_dir = no_repeat_dir / \"person_res\"\n",
    "all_persona = []\n",
    "\n",
    "for model_dir in sorted(persona_dir.iterdir()):\n",
    "    if model_dir.is_dir():\n",
    "        model_name = model_dir.name.replace(\"_res\", \"\")\n",
    "        records = load_all_games(model_dir)\n",
    "        for r in records:\n",
    "            r[\"model\"] = model_name\n",
    "        all_persona.extend(records)\n",
    "\n",
    "df_persona = pd.DataFrame(all_persona)\n",
    "df_persona[\"game_type\"] = df_persona[\"filename\"].apply(classify_game)\n",
    "\n",
    "print(f\"Persona records loaded: {df_persona.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 4. Data Schema & Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Baseline Data Schema ===\")\n",
    "print(f\"Columns: {list(df_baseline.columns)}\")\n",
    "print(f\"Shape: {df_baseline.shape}\")\n",
    "print(f\"\\n=== Game Type Distribution (Baseline) ===\")\n",
    "print(df_baseline[\"game_type\"].value_counts().to_string())\n",
    "print(f\"\\n=== Sample Rows ===\")\n",
    "df_baseline.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample BDI responses from Trust Game with persona\n",
    "trust_game = df_persona[df_persona[\"game_type\"] == \"Trust Game\"]\n",
    "if len(trust_game) > 0:\n",
    "    for i, row in trust_game.head(2).iterrows():\n",
    "        print(f\"--- Model: {row['model']} | Decision: ${row['decision']:.0f} ---\")\n",
    "        persona_text = row[\"persona\"][:200] if isinstance(row[\"persona\"], str) else \"\"\n",
    "        print(f\"Persona: {persona_text}...\")\n",
    "        response_text = row[\"response\"][:300] if isinstance(row[\"response\"], str) else \"\"\n",
    "        print(f\"BDI Response: {response_text}...\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 5. Exploratory Data Analysis\n",
    "\n",
    "### 5.1 Trust Game: Giving Amount by Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "trust_baseline = df_baseline[df_baseline[\"game_type\"] == \"Trust Game\"].copy()\n",
    "trust_baseline[\"decision\"] = pd.to_numeric(trust_baseline[\"decision\"], errors=\"coerce\")\n",
    "trust_baseline = trust_baseline.dropna(subset=[\"decision\"])\n",
    "\n",
    "if len(trust_baseline) > 0:\n",
    "    model_order = (trust_baseline.groupby(\"model\")[\"decision\"]\n",
    "                   .mean().sort_values(ascending=False).index)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(data=trust_baseline, x=\"model\", y=\"decision\",\n",
    "                order=model_order, hue=\"model\", palette=\"Set2\", legend=False)\n",
    "    plt.title(\"Trust Game: Distribution of Giving Amount by Model\")\n",
    "    plt.xlabel(\"Model\")\n",
    "    plt.ylabel(\"Amount Given ($)\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Mean giving amount per model:\")\n",
    "    print(trust_baseline.groupby(\"model\")[\"decision\"]\n",
    "          .agg([\"mean\", \"median\", \"std\"]).round(2)\n",
    "          .sort_values(\"mean\", ascending=False).to_string())\n",
    "else:\n",
    "    print(\"No Trust Game data found in baseline.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "### 5.2 Dictator Game: Giving Amount by Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictator_baseline = df_baseline[df_baseline[\"game_type\"] == \"Dictator Game\"].copy()\n",
    "dictator_baseline[\"decision\"] = pd.to_numeric(dictator_baseline[\"decision\"], errors=\"coerce\")\n",
    "dictator_baseline = dictator_baseline.dropna(subset=[\"decision\"])\n",
    "\n",
    "if len(dictator_baseline) > 0:\n",
    "    model_order = (dictator_baseline.groupby(\"model\")[\"decision\"]\n",
    "                   .mean().sort_values(ascending=False).index)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(data=dictator_baseline, x=\"model\", y=\"decision\",\n",
    "                order=model_order, hue=\"model\", palette=\"Set3\", legend=False)\n",
    "    plt.title(\"Dictator Game: Distribution of Giving Amount by Model\")\n",
    "    plt.xlabel(\"Model\")\n",
    "    plt.ylabel(\"Amount Given ($)\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No Dictator Game data found in baseline.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19a",
   "metadata": {},
   "source": [
    "### 5.3 Trust Game vs Dictator Game Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "monetary_games = df_baseline[\n",
    "    df_baseline[\"game_type\"].isin([\"Trust Game\", \"Dictator Game\"])\n",
    "].copy()\n",
    "monetary_games[\"decision\"] = pd.to_numeric(monetary_games[\"decision\"], errors=\"coerce\")\n",
    "monetary_games = monetary_games.dropna(subset=[\"decision\"])\n",
    "\n",
    "if len(monetary_games) > 0:\n",
    "    comparison = (monetary_games.groupby([\"model\", \"game_type\"])[\"decision\"]\n",
    "                  .mean().unstack(fill_value=0))\n",
    "\n",
    "    comparison.plot(kind=\"bar\", figsize=(12, 6), color=[\"steelblue\", \"coral\"])\n",
    "    plt.title(\"Mean Giving Amount: Trust Game vs Dictator Game\")\n",
    "    plt.xlabel(\"Model\")\n",
    "    plt.ylabel(\"Mean Amount Given ($)\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.legend(title=\"Game Type\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "### 5.4 Effect of Persona on Trust Decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare baseline (no persona) vs persona-based Trust Game\n",
    "bl_trust = df_baseline[df_baseline[\"game_type\"] == \"Trust Game\"].copy()\n",
    "bl_trust[\"decision\"] = pd.to_numeric(bl_trust[\"decision\"], errors=\"coerce\")\n",
    "trust_bl_mean = bl_trust.dropna(subset=[\"decision\"]).groupby(\"model\")[\"decision\"].mean()\n",
    "\n",
    "ps_trust = df_persona[df_persona[\"game_type\"] == \"Trust Game\"].copy()\n",
    "ps_trust[\"decision\"] = pd.to_numeric(ps_trust[\"decision\"], errors=\"coerce\")\n",
    "trust_ps_mean = ps_trust.dropna(subset=[\"decision\"]).groupby(\"model\")[\"decision\"].mean()\n",
    "\n",
    "compare_df = pd.DataFrame({\n",
    "    \"Baseline (no persona)\": trust_bl_mean,\n",
    "    \"With Persona\": trust_ps_mean\n",
    "}).dropna()\n",
    "\n",
    "if len(compare_df) > 0:\n",
    "    compare_df.plot(kind=\"bar\", figsize=(10, 5), color=[\"steelblue\", \"coral\"])\n",
    "    plt.title(\"Effect of Persona on Trust Game Giving Amount\")\n",
    "    plt.xlabel(\"Model\")\n",
    "    plt.ylabel(\"Mean Amount Given ($)\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.legend(title=\"Condition\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Difference (Persona - Baseline):\")\n",
    "    diff = (compare_df[\"With Persona\"] - compare_df[\"Baseline (no persona)\"]).round(2)\n",
    "    print(diff.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "### 5.5 Demographic Variants: Trust Game Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_dirs = {\n",
    "    \"Male\": \"male_res\",\n",
    "    \"Female\": \"female_res\",\n",
    "    \"African American\": \"African American_res\",\n",
    "    \"Asian American\": \"Asian American_res\",\n",
    "    \"Latino American\": \"Latino American_res\",\n",
    "    \"White American\": \"White American_res\",\n",
    "}\n",
    "\n",
    "demo_results = {}\n",
    "for label, dirname in demographic_dirs.items():\n",
    "    variant_dir = no_repeat_dir / dirname\n",
    "    if not variant_dir.exists():\n",
    "        continue\n",
    "    all_records = []\n",
    "    for model_dir in sorted(variant_dir.iterdir()):\n",
    "        if model_dir.is_dir():\n",
    "            model_name = model_dir.name.replace(\"_res\", \"\")\n",
    "            records = load_all_games(model_dir)\n",
    "            for r in records:\n",
    "                r[\"model\"] = model_name\n",
    "            all_records.extend(records)\n",
    "    df_var = pd.DataFrame(all_records)\n",
    "    if len(df_var) == 0:\n",
    "        continue\n",
    "    df_var[\"game_type\"] = df_var[\"filename\"].apply(classify_game)\n",
    "    trust_var = df_var[df_var[\"game_type\"] == \"Trust Game\"].copy()\n",
    "    trust_var[\"decision\"] = pd.to_numeric(trust_var[\"decision\"], errors=\"coerce\")\n",
    "    trust_var = trust_var.dropna(subset=[\"decision\"])\n",
    "    if len(trust_var) > 0:\n",
    "        demo_results[label] = trust_var[\"decision\"].mean()\n",
    "\n",
    "if demo_results:\n",
    "    demo_df = pd.Series(demo_results).sort_values(ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    bars = plt.bar(demo_df.index, demo_df.values, color=\"mediumseagreen\",\n",
    "                   edgecolor=\"white\")\n",
    "    plt.title(\"Trust Game: Mean Giving Amount by Demographic Persona\")\n",
    "    plt.ylabel(\"Mean Amount Given ($)\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    for bar, val in zip(bars, demo_df.values):\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.1,\n",
    "                 f\"${val:.1f}\", ha=\"center\", va=\"bottom\", fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No demographic variant data found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "### 5.6 Game Type Distribution & Record Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Game type distribution\n",
    "game_counts = df_baseline[\"game_type\"].value_counts()\n",
    "axes[0].barh(game_counts.index, game_counts.values, color=\"steelblue\",\n",
    "             edgecolor=\"white\")\n",
    "axes[0].set_title(\"Records per Game Type (Baseline)\")\n",
    "axes[0].set_xlabel(\"Number of Records\")\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# Model distribution\n",
    "model_counts = df_baseline[\"model\"].value_counts()\n",
    "axes[1].barh(model_counts.index, model_counts.values, color=\"coral\",\n",
    "             edgecolor=\"white\")\n",
    "axes[1].set_title(\"Records per Model (Baseline)\")\n",
    "axes[1].set_xlabel(\"Number of Records\")\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "### 5.7 Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = df_baseline.copy()\n",
    "df_numeric[\"decision\"] = pd.to_numeric(df_numeric[\"decision\"], errors=\"coerce\")\n",
    "summary = (df_numeric.dropna(subset=[\"decision\"])\n",
    "           .groupby([\"game_type\", \"model\"])[\"decision\"]\n",
    "           .agg([\"count\", \"mean\", \"std\", \"min\", \"max\"])\n",
    "           .round(2))\n",
    "\n",
    "print(\"=== Summary Statistics (Baseline) ===\")\n",
    "print(summary.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "## 6. Key Observations\n",
    "\n",
    "1. **BDI Framework:** Each agent articulates Belief, Desire, and Intention before\n",
    "   making a decision, providing interpretable reasoning traces for game-theoretic analysis.\n",
    "\n",
    "2. **Model differences:** Different LLMs exhibit distinct trust/generosity profiles.\n",
    "   GPT-4 tends to be more \"generous\" in trust games compared to smaller models.\n",
    "\n",
    "3. **Persona effects:** Assigning demographic personas to agents can shift their\n",
    "   trust behavior, revealing potential biases embedded in LLMs.\n",
    "\n",
    "4. **Trust vs. Dictator:** Agents often give more in Trust Games (where reciprocation\n",
    "   is possible) than in Dictator Games, mirroring human behavioral patterns.\n",
    "\n",
    "5. **Research relevance (IS/AI):**\n",
    "   - **Agent alignment:** Evaluate whether LLM agents align with rational or prosocial norms\n",
    "   - **Bias detection:** Test if demographic personas cause disparate trust behavior\n",
    "   - **Multi-agent simulation:** Build game-theoretic environments for agent interaction research\n",
    "   - **Behavioral economics:** Use LLMs as proxies for human subjects in economic experiments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}