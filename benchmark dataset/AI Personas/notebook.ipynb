{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 4. AI Personas (PersonaHub)\n",
    "**Category:** AI Agent Core Capabilities\n",
    "\n",
    "**Source:** [Tencent AI Lab - PersonaHub](https://github.com/tencent-ailab/persona-hub) |\n",
    "[HuggingFace](https://huggingface.co/datasets/proj-persona/PersonaHub)\n",
    "\n",
    "**Description:** Used to train User Simulators, enabling agents to role-play\n",
    "specific demographic backgrounds for large-scale social simulation.\n",
    "\n",
    "**Data Content:** A vast collection of synthetic user persona descriptions\n",
    "and their behavioral reaction data within specific contexts.\n",
    "\n",
    "**Paper:** [Scaling Synthetic Data Creation with 1,000,000,000 Personas](https://arxiv.org/abs/2406.20094)\n",
    "\n",
    "---\n",
    "\n",
    "**This notebook covers:**\n",
    "1. Data loading from HuggingFace (persona, instruction, math, npc subsets)\n",
    "2. Schema exploration & sample persona descriptions\n",
    "3. Persona description length analysis (chars & words)\n",
    "4. Top keywords & role category distribution\n",
    "5. Cross-subset text length comparison\n",
    "6. Instruction description type analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (uncomment if needed)\n",
    "# !pip install datasets pandas matplotlib seaborn wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from datasets import load_dataset\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "plt.rcParams[\"axes.titlesize\"] = 13\n",
    "plt.rcParams[\"axes.labelsize\"] = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Dataset Overview\n",
    "\n",
    "PersonaHub releases **8 subsets**:\n",
    "\n",
    "| Subset | Rows | Description |\n",
    "|--------|------|-------------|\n",
    "| `persona` | 200,000 | Core persona descriptions |\n",
    "| `instruction` | 50,000 | Persona-driven instructions |\n",
    "| `math` | 50,000 | Persona-driven math problems |\n",
    "| `reasoning` | 50,000 | Persona-driven logical reasoning |\n",
    "| `knowledge` | 10,000 | Persona-driven knowledge-rich texts |\n",
    "| `npc` | 10,000 | Game NPC personas |\n",
    "| `tool` | 5,000 | Persona-driven tool/function descriptions |\n",
    "| `elite_persona` | 370M | Full-scale persona collection (too large to load here) |\n",
    "\n",
    "We focus on the **persona**, **instruction**, **math**, and **npc** subsets below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 3. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load main subsets from HuggingFace\n",
    "print(\"Loading persona subset (200k rows)...\")\n",
    "ds_persona = load_dataset(\"proj-persona/PersonaHub\", name=\"persona\", split=\"train\")\n",
    "\n",
    "print(\"Loading instruction subset (50k rows)...\")\n",
    "ds_instruction = load_dataset(\"proj-persona/PersonaHub\", name=\"instruction\", split=\"train\")\n",
    "\n",
    "print(\"Loading math subset (50k rows)...\")\n",
    "ds_math = load_dataset(\"proj-persona/PersonaHub\", name=\"math\", split=\"train\")\n",
    "\n",
    "print(\"Loading npc subset (10k rows)...\")\n",
    "ds_npc = load_dataset(\"proj-persona/PersonaHub\", name=\"npc\", split=\"train\")\n",
    "\n",
    "print(\"\\nAll subsets loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrames for easier analysis\n",
    "df_persona = ds_persona.to_pandas()\n",
    "df_instruction = ds_instruction.to_pandas()\n",
    "df_math = ds_math.to_pandas()\n",
    "df_npc = ds_npc.to_pandas()\n",
    "\n",
    "print(f\"Persona subset:     {df_persona.shape}\")\n",
    "print(f\"Instruction subset: {df_instruction.shape}\")\n",
    "print(f\"Math subset:        {df_math.shape}\")\n",
    "print(f\"NPC subset:         {df_npc.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 4. Data Schema & Samples\n",
    "\n",
    "### 4.1 Persona Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Persona Subset ===\")\n",
    "print(f\"Columns: {list(df_persona.columns)}\")\n",
    "print(f\"Shape: {df_persona.shape}\\n\")\n",
    "df_persona.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample persona descriptions\n",
    "print(\"=== Sample Persona Descriptions ===\\n\")\n",
    "for i in range(5):\n",
    "    print(f\"[{i+1}] {df_persona['persona'].iloc[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "### 4.2 Instruction Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Instruction Subset ===\")\n",
    "print(f\"Columns: {list(df_instruction.columns)}\")\n",
    "print(f\"Shape: {df_instruction.shape}\\n\")\n",
    "df_instruction.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample instruction entries\n",
    "for i in range(2):\n",
    "    print(f\"--- Instruction {i+1} ---\")\n",
    "    print(f\"Input Persona:    {df_instruction['input persona'].iloc[i][:150]}...\")\n",
    "    print(f\"Synthesized Text: {df_instruction['synthesized text'].iloc[i][:200]}...\")\n",
    "    print(f\"Description:      {df_instruction['description'].iloc[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 5. Exploratory Data Analysis\n",
    "\n",
    "### 5.1 Persona Description Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persona[\"char_len\"] = df_persona[\"persona\"].astype(str).apply(len)\n",
    "df_persona[\"word_count\"] = df_persona[\"persona\"].astype(str).apply(\n",
    "    lambda x: len(x.split())\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(df_persona[\"char_len\"], bins=50, color=\"steelblue\",\n",
    "             edgecolor=\"white\")\n",
    "axes[0].set_title(\"Persona Description Length (characters)\")\n",
    "axes[0].set_xlabel(\"Character Count\")\n",
    "axes[0].set_ylabel(\"Frequency\")\n",
    "\n",
    "axes[1].hist(df_persona[\"word_count\"], bins=50, color=\"coral\",\n",
    "             edgecolor=\"white\")\n",
    "axes[1].set_title(\"Persona Description Length (words)\")\n",
    "axes[1].set_xlabel(\"Word Count\")\n",
    "axes[1].set_ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Character length - Mean: {df_persona['char_len'].mean():.0f}, \"\n",
    "      f\"Median: {df_persona['char_len'].median():.0f}, \"\n",
    "      f\"Max: {df_persona['char_len'].max()}\")\n",
    "print(f\"Word count - Mean: {df_persona['word_count'].mean():.1f}, \"\n",
    "      f\"Median: {df_persona['word_count'].median():.0f}, \"\n",
    "      f\"Max: {df_persona['word_count'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "### 5.2 Top Keywords in Persona Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract most frequent meaningful words (skip common stopwords)\n",
    "stopwords = {\n",
    "    \"a\", \"an\", \"the\", \"and\", \"or\", \"of\", \"in\", \"to\", \"for\", \"is\", \"are\",\n",
    "    \"was\", \"were\", \"be\", \"been\", \"being\", \"has\", \"have\", \"had\", \"do\", \"does\",\n",
    "    \"did\", \"will\", \"would\", \"could\", \"should\", \"may\", \"might\", \"can\", \"with\",\n",
    "    \"at\", \"by\", \"from\", \"on\", \"as\", \"it\", \"its\", \"this\", \"that\", \"their\",\n",
    "    \"who\", \"which\", \"what\", \"where\", \"when\", \"how\", \"not\", \"no\", \"but\", \"if\",\n",
    "    \"about\", \"into\", \"through\", \"during\", \"before\", \"after\", \"between\", \"all\",\n",
    "    \"each\", \"every\", \"both\", \"such\", \"than\", \"too\", \"very\", \"also\", \"just\",\n",
    "    \"so\", \"more\", \"most\", \"other\", \"some\", \"any\", \"they\", \"them\", \"he\", \"she\",\n",
    "    \"his\", \"her\", \"him\", \"we\", \"our\", \"you\", \"your\",\n",
    "}\n",
    "\n",
    "all_words = []\n",
    "for text in df_persona[\"persona\"].astype(str):\n",
    "    words = text.lower().split()\n",
    "    all_words.extend(\n",
    "        w.strip(\".,;:!?()\\\"'\")\n",
    "        for w in words\n",
    "        if w.strip(\".,;:!?()\\\"'\") not in stopwords and len(w) > 2\n",
    "    )\n",
    "\n",
    "word_freq = Counter(all_words).most_common(30)\n",
    "words, counts = zip(*word_freq)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.barh(range(len(words)), counts, color=\"steelblue\", edgecolor=\"white\")\n",
    "plt.yticks(range(len(words)), words)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Top 30 Keywords in Persona Descriptions\")\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "### 5.3 Persona Role Categories\n",
    "\n",
    "We extract role-related keywords to understand the distribution of persona types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "role_keywords = {\n",
    "    \"Professional/Expert\": [\"expert\", \"specialist\", \"professional\", \"analyst\",\n",
    "                            \"consultant\", \"advisor\"],\n",
    "    \"Student/Learner\": [\"student\", \"learner\", \"studying\", \"undergraduate\",\n",
    "                        \"graduate\"],\n",
    "    \"Teacher/Educator\": [\"teacher\", \"professor\", \"educator\", \"instructor\",\n",
    "                         \"tutor\"],\n",
    "    \"Engineer/Developer\": [\"engineer\", \"developer\", \"programmer\", \"software\",\n",
    "                           \"architect\"],\n",
    "    \"Researcher/Scientist\": [\"researcher\", \"scientist\", \"academic\", \"scholar\"],\n",
    "    \"Artist/Creative\": [\"artist\", \"designer\", \"writer\", \"musician\", \"creative\"],\n",
    "    \"Healthcare\": [\"doctor\", \"nurse\", \"physician\", \"therapist\", \"medical\"],\n",
    "    \"Business/Manager\": [\"manager\", \"entrepreneur\", \"business\", \"executive\",\n",
    "                         \"ceo\"],\n",
    "}\n",
    "\n",
    "persona_lower = df_persona[\"persona\"].astype(str).str.lower()\n",
    "role_counts = {}\n",
    "for role, keywords in role_keywords.items():\n",
    "    role_counts[role] = persona_lower.apply(\n",
    "        lambda x: any(kw in x for kw in keywords)\n",
    "    ).sum()\n",
    "\n",
    "role_df = (pd.DataFrame(list(role_counts.items()),\n",
    "                        columns=[\"Role Category\", \"Count\"])\n",
    "           .sort_values(\"Count\", ascending=False))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "bars = plt.barh(role_df[\"Role Category\"], role_df[\"Count\"],\n",
    "                color=\"coral\", edgecolor=\"white\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Persona Role Categories (keyword-based classification)\")\n",
    "plt.xlabel(\"Number of Personas\")\n",
    "for bar, val in zip(bars, role_df[\"Count\"]):\n",
    "    plt.text(bar.get_width() + 200, bar.get_y() + bar.get_height() / 2,\n",
    "             f\"{val:,}\", va=\"center\", fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Note: Categories are not mutually exclusive; \"\n",
    "      \"one persona may match multiple categories.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "### 5.4 Cross-Subset Comparison: Text Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = {\n",
    "    \"Persona (description)\": df_persona[\"persona\"].astype(str),\n",
    "    \"Instruction (synthesized)\": df_instruction[\"synthesized text\"].astype(str),\n",
    "    \"Math (synthesized)\": df_math[\"synthesized text\"].astype(str),\n",
    "    \"NPC (synthesized)\": df_npc[\"synthesized text\"].astype(str),\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "colors = [\"steelblue\", \"coral\", \"mediumseagreen\", \"orchid\"]\n",
    "\n",
    "for ax, (name, texts), color in zip(axes.flat, subsets.items(), colors):\n",
    "    lengths = texts.apply(len)\n",
    "    ax.hist(lengths, bins=50, color=color, edgecolor=\"white\", alpha=0.8)\n",
    "    ax.set_title(f\"{name}\\nMean={lengths.mean():.0f} chars, \"\n",
    "                 f\"Median={lengths.median():.0f}\")\n",
    "    ax.set_xlabel(\"Character Count\")\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "\n",
    "plt.suptitle(\"Text Length Distribution Across Subsets\", fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "### 5.5 Instruction Description Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_counts = df_instruction[\"description\"].value_counts().head(15)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "desc_counts.plot(kind=\"barh\", color=\"mediumseagreen\", edgecolor=\"white\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Top 15 Instruction Description Types\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Description\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total unique description types: {df_instruction['description'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "### 5.6 Subset Size Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame({\n",
    "    \"Subset\": [\"persona\", \"instruction\", \"math\", \"npc\"],\n",
    "    \"Rows\": [len(df_persona), len(df_instruction), len(df_math), len(df_npc)],\n",
    "    \"Columns\": [df_persona.shape[1], df_instruction.shape[1],\n",
    "                df_math.shape[1], df_npc.shape[1]],\n",
    "    \"Avg Text Length (chars)\": [\n",
    "        df_persona[\"persona\"].astype(str).apply(len).mean(),\n",
    "        df_instruction[\"synthesized text\"].astype(str).apply(len).mean(),\n",
    "        df_math[\"synthesized text\"].astype(str).apply(len).mean(),\n",
    "        df_npc[\"synthesized text\"].astype(str).apply(len).mean(),\n",
    "    ],\n",
    "})\n",
    "summary[\"Avg Text Length (chars)\"] = (summary[\"Avg Text Length (chars)\"]\n",
    "                                      .round(0).astype(int))\n",
    "\n",
    "print(\"=== Subset Size Summary ===\")\n",
    "print(summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "## 6. Key Observations\n",
    "\n",
    "1. **Scale:** PersonaHub provides 200k curated personas (and 370M elite personas),\n",
    "   making it one of the largest persona collections available for research.\n",
    "\n",
    "2. **Diversity:** Personas span a wide range of roles \u2014 from engineers and researchers\n",
    "   to artists, educators, and healthcare professionals \u2014 enabling diverse user simulation.\n",
    "\n",
    "3. **Multi-purpose:** Beyond persona descriptions, the dataset includes\n",
    "   persona-driven synthesized content (instructions, math, reasoning, NPC, tools),\n",
    "   demonstrating how personas can drive diverse data generation.\n",
    "\n",
    "4. **Concise descriptions:** Persona descriptions are relatively short and focused,\n",
    "   making them practical as prompts or system instructions for LLMs.\n",
    "\n",
    "5. **Research relevance (IS/AI):**\n",
    "   - **User simulation:** Train agents to mimic specific demographics for A/B testing\n",
    "   - **Synthetic data generation:** Use personas as seeds for creating diverse training data\n",
    "   - **Social simulation:** Build multi-agent systems where each agent has a distinct persona\n",
    "   - **Bias auditing:** Test model behavior across different persona backgrounds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}