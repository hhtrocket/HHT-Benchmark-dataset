# ðŸ“š Benchmark Datasets Collection

## ðŸ”¹ Category 1: Data Quality & Annotation

### 1. Bitext Customer Support
- **Description:** Designed to train customer service agents in intent recognition and breakdown analysis, testing the AI's ability to accurately understand user needs.
- **Data Content:** Contains customer service corpora with 27 specific intents such as order checks and refunds, 100 slot tags, and dialog breakdown markers.
- **Reference:** [HuggingFace Link](https://huggingface.co/datasets/bitext/Bitext-customer-support-llm-chatbot-training-dataset)

### 2. Fear Speech Dataset
- **Description:** Used for AI Safety Alignment, specifically designed to detect implicit fear speech that is not profane but is maliciously inflammatory.
- **Data Content:** Approximately 40,000 posts from the Gab platform, manually annotated as fear speech, hate speech, or normal.
- **Reference:** [GitHub Repository](https://github.com/punyajoy/Fearspeech-project)

### 3. High Agreement Summarization
- **Description:** Used to train agents to generate hallucination-free summaries, emphasizing extremely high consistency in human annotation as the gold standard.
- **Data Content:** News documents paired with high-quality human summaries that have undergone rigorous denoising and consistency filtering.
- **Reference:** [GitHub Repository](https://github.com/GEM-benchmark/MTurkRequirementPipeline)



## ðŸ”¸ Category 2: AI Agent Core Capabilities

### 4. AI Personas
- **Description:** Used to train User Simulators, enabling agents to role-play specific demographic backgrounds for large-scale social simulation.
- **Data Content:** A vast collection of synthetic user persona descriptions and their behavioral reaction data within specific contexts.
- **Reference:** [GitHub Repository](https://github.com/tencent-ailab/persona-hub)

### 5. Agent Trust Behavior
- **Description:** Used for game theory research to train agents on decision-making logic regarding trust, betrayal, and reciprocity.
- **Data Content:** Multi-turn interaction logs from Trust Games, including records of the agent's Belief, Desire, and Intention.
- **Reference:** [GitHub Repository](https://github.com/camel-ai/agent-trust)

### 6. Thought Source
- **Description:** Designed to enhance agent reasoning capabilities using Chain-of-Thought data.
- **Data Content:** A collection of triplets consisting of Questions, Detailed Rationales or intermediate reasoning steps, and Final Answers.
- **Reference:** [GitHub Repository](https://github.com/OpenBioLink/ThoughtSource)

### 7. Automatic Prompt Optimization
- **Description:** Used to train self-reflective agents capable of automatically analyzing error logs and optimizing their own instructions.
- **Data Content:** Prompt optimization trajectory data (Original Instruction -> Error Analysis -> Optimized Instruction).
- **Reference:** [GitHub Repository](https://github.com/pree-dew/protegi)

### 8. Evaluator Agent Benchmark
- **Description:** Used to train Critic Agents specifically for evaluating the dialogue quality generated by other agents.
- **Data Content:** Multi-dimensional dialogue evaluation data, comparing LLM scores with human ratings.
- **Reference:** [GitHub Repository](https://github.com/e0397123/comp-analysis)

### 9. OpinionQA and Persona Effect Quantified
- **Description:** Used to train agent role consistency and de-biasing, verifying if AI can authentically simulate roles.
- **Data Content:** Public opinion poll questions and LLM response distribution data under different role settings (age, gender, etc.).
- **Reference:** [GitHub Repository](https://github.com/cambridgeltl/persona_effect)

### 10. Human Attention Maps
- **Description:** Used to train Explainability Agents, teaching models to focus on key information like human attention patterns.
- **Data Content:** Yelp review texts paired with attention weights for each word derived from human reading behavior.
- **Reference:** [GitHub Repository](https://github.com/cansusen/Human-Attention-for-Text-Classification)
